<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>transR</title>
      <link href="/2020/02/29/transr/"/>
      <url>/2020/02/29/transr/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>TransE还是TransH都是将实体和关系映射同一个空间，但是，一个实体可能具有多个层面的信息，不同的关系可能关注不同层面的实体。实体和关系表达的最佳维度并不一定是一致的，因此，<strong>映射到同一个空间可能会限制模型效果。</strong></p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>分析TransE，TransH存在的问题</li><li>TransR</li><li>CTransR</li></ul><h2 id="TransH存在的问题"><a href="#TransH存在的问题" class="headerlink" title="TransH存在的问题"></a>TransH存在的问题</h2><p>虽然TransH模型使得同一实体在不同关系下通过投影有了不同的表示，但投影之后仍然处于原来的空间 $R^𝑛$ 中，这里表示实体向量和关系向量均为$𝑛$维。换言之，TransH模型假设实体和关系处于相同的语义空间中，这在一定程度上限制了它的表示能力。</p><h2 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h2><ul><li><p>设计理念</p><p>一个实体是多种属性的综合体，不同关系关注实体的不同属性。直觉上一些相似的实体在实体空间中应该彼此靠近，但是同样地，在一些特定的不同的方面在对应的关系空间中应该彼此远离。为了解决这个问题，==我们提出了一种新的方法，将实体和关系投影到不同的空间中，也就是实体空间和多元关系空间（也即是特定关系的实体空间），在对应的关系空间上实现翻译。因此命名为TransR。==</p></li><li><p>核心思想</p><ul><li>TransH模型是为每个关系假定一超平面，将实体投影到这个超平面上进行翻译；而TransR模型是为每个关系假定一语义空间 $R^m$ ，将实体映射到这个语义空间上进行翻译。这里$m$表示示关系向量的维度为$𝑚$。</li><li>对于每个元组$(h,r,t)$，首先将实体空间中的实体 $\textbf{h},\textbf{t}(\textbf{h},\textbf{t} \in R^d)$ 通过矩阵 $\textbf{M}_r(\textbf{M}_r \in R^{k \times d})$ 向关系 $\textbf{r}(\textbf{r} \in R^k)$ 投影得到$\textbf{h}_r$和$\textbf{t}_r$，然后使$\textbf{h}_r+\textbf{r}≈\textbf{t}_r$。特定的关系投影（彩色的圆圈表示）能够使得头/尾实体在这个关系下真实的靠近彼此，使得不具有此关系（彩色的三角形表示）的实体彼此远离。</li></ul><p><img src="/images/transR/1.png" alt="1"></p><ul><li>投影向量<script type="math/tex; mode=display">\textbf{h}_r=\textbf{hM}_r,\textbf{t}_r=\textbf{tM}_r</script></li></ul></li><li><p>得分函数</p><script type="math/tex; mode=display">  f_r(h,t)=\Vert \textbf{h}_r+\textbf{r}−\textbf{t}_r\Vert_2^2</script></li><li><p>正则约束</p><script type="math/tex; mode=display">  其中\textbf{h},\textbf{t}∈R^n,\textbf{r}∈R^m,\textbf{M}_r∈R^{n×m} , \textbf{h},\textbf{r},\textbf{t},\textbf{hM}_r,\textbf{tM}_r的L_2范数均小于等于1</script><ul><li>基于边际的代价函数</li></ul><script type="math/tex; mode=display">  L=\sum_{(h, r, t) \in S\left(k^{\prime}, r, t^{\prime}\right) \in S^{\prime}} \max \left(0, f_{r}(h, t)+\gamma-f_{r}\left(h^{\prime}, t^{\prime}\right)\right)</script></li></ul><h2 id="CTransR"><a href="#CTransR" class="headerlink" title="CTransR"></a>CTransR</h2><ul><li><p>提出原因</p><p>在一个特定的关系下，头-尾实体对通常展示出不同的模型。仅仅通过单个的关系向量还不足以建立实现从头实体到尾实体的所有翻译。例如，具有关系 $(location,location,contains)$ 头-尾实体有很多模式，如$country-city$ ，$country-university$ ，$continent-country$ 等等。沿着分段线性回归（Ritzema and others 1994）的思想，通过对不同的头-尾实体对聚类分组和学习每组的关系向量，我们进一步提出了基于聚类的CTransR。</p></li><li><p>核心思想</p><p>CTransR的意思是Cluster-based TransR. CTransR首先对于每个关系$r$所对应的三元组$(h,r,t)$，先通过TransE学习 $\textbf{h,t}$，然后依据 $\textbf{h-t}$ 进行AP聚类（一种不需要指定类别数的聚类方法），从而将关系 $\textbf{r}$ 分解为更细粒度的子关系 $r_c$ ，CTransR对每个 $r_c$ 分别学习相应的向量表示 $\textbf{r}_c$ 。</p></li><li><p>投影向量</p><script type="math/tex; mode=display">\textbf{h}_{r,c}=\textbf{hM}_r,\textbf{t}_{r,c}=\textbf{tM}_r</script></li><li><p>得分函数</p><script type="math/tex; mode=display">fr(h,t)=\Vert \textbf{h}_{r,c}+\textbf{r}_c−\textbf{t}_{r,c}\Vert_2^2+α\Vert \textbf{r}_c−\textbf{r}\Vert_2^2\\</script></li></ul><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h3><ul><li><p><strong>任务</strong></p><p>链接预测指的是对于给定关系和关系的一个实体，预测另外一个实体，例如给定 $(r,t)$  预测 $h$ ,或者是给定 $(h,r)$ 预测 $t$ 。</p></li><li><p><strong>评估标准</strong></p><ul><li>正确实体的平均排名</li><li>正确实体排在前10位的几率（Hist@10）</li></ul></li><li><p><strong>过滤</strong></p><p>生成的负例三元组可能原本就存在于知识图谱中，需要删去；</p></li></ul><h3 id="三元组分类"><a href="#三元组分类" class="headerlink" title="三元组分类"></a>三元组分类</h3><ul><li><p><strong>任务</strong></p><p>判断给定的三元组 $(h,r,t)$ 是否正确，这是一个二分类问题。</p></li><li><p><strong>评估标准</strong></p><p>对于给定的三元组 $(h,r,t)$ ，我们设置一个阈值 $\delta_r$ ，如果三元组的得分函数小于 $\delta_r$ ，则被归为正类，否则被归为负类。</p></li></ul><h3 id="关系提取"><a href="#关系提取" class="headerlink" title="关系提取"></a>关系提取</h3><ul><li><p><strong>任务</strong></p><p>关系提取旨在从大规模纯文本中提取关系事实，这是丰富知识图谱的重要信息来源。</p></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> KG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Trans系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch数据处理</title>
      <link href="/2020/02/27/pytorch-shu-ju-chu-li/"/>
      <url>/2020/02/27/pytorch-shu-ju-chu-li/</url>
      
        <content type="html"><![CDATA[<h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><h4 id="一个数据集需要具备哪些功能？"><a href="#一个数据集需要具备哪些功能？" class="headerlink" title="一个数据集需要具备哪些功能？"></a><strong>一个数据集需要具备哪些功能？</strong></h4><ul><li>获取每一个数据及其label</li><li>获取数据集的大小（size）</li></ul><h4 id="数据集的组织形式"><a href="#数据集的组织形式" class="headerlink" title="数据集的组织形式"></a>数据集的组织形式</h4><ul><li>数据集是单独文件夹和对应的标签集单独一个文件夹</li><li>数据集是单独一个文件夹，label是每一个数据的文件名</li><li>数据集是单独一个文件夹，文件夹的名字是该分类的label</li></ul><h4 id="DataSet类"><a href="#DataSet类" class="headerlink" title="DataSet类"></a>DataSet类</h4><p><code>Dataset</code>是一个抽象类，如果想要创建自己的数据集的话，或者说，想要用<code>Pytorch</code>的库来进入数据加载的话，是需要继承这个<code>Dataset</code>抽象类的。同时需要重写这个类的函数的魔法函数<code>__item__()</code>和<code>__len__()</code>。</p><h3 id="设计代码"><a href="#设计代码" class="headerlink" title="设计代码"></a>设计代码</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8"""Author: ywfanEmail: 1640788287@qq.comdate: 2020/2/25 18:45"""from torch.utils.data import Datasetimport osimport matplotlib.pyplot as pltclass MyData(Dataset):    def __init__(self, datas_dir, labels_dir):        """        :param datas_dir: 数据集的地址        :param labels_dir: 数据集对应标签的地址        """        self.datas_dir = datas_dir        self.labels_dir = labels_dir        # 获取数据集和对应标签的文件名，各自存储在列表中        self.images = os.listdir(self.datas_dir)        self.labels = os.listdir(self.labels_dir)    def __getitem__(self, idx):        img_name = self.images[idx]        label_name = self.labels[idx]        img_path = os.path.join(self.datas_dir, img_name)        label_path = os.path.join(self.labels_dir, label_name)        img = plt.imread(img_path)        with open(label_path) as fp:            label = fp.read()        return img, label    def __len__(self):        return len(self.images)if __name__ == '__main__':    # ------数据集1的地址------    datas1_dir = "data/train/ants_image"    labels1_dir = "data/train/ants_label"    my_data1 = MyData(datas1_dir,labels1_dir)    # ------数据集2的地址------    datas2_dir = "data/train/bees_image"    labels2_dir = "data/train/bees_label"    my_data2 = MyData(datas2_dir, labels2_dir)    # 整合数据，形成一个数据集    my_data = my_data1+my_data2    img, label = my_data[123]    plt.imshow(img)    plt.show()    print(label)    print(len(my_data))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch-notes</title>
      <link href="/2020/02/26/pytorch-notes/"/>
      <url>/2020/02/26/pytorch-notes/</url>
      
        <content type="html"><![CDATA[<h2 id="张量简介"><a href="#张量简介" class="headerlink" title="张量简介"></a>张量简介</h2><h2 id="Tensor与Variable"><a href="#Tensor与Variable" class="headerlink" title="Tensor与Variable"></a>Tensor与Variable</h2><h3 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h3><p>variable是torch.autograd中的数据类型，主要用于封装Tensor，进行自动求导</p><ul><li>data：被包装的Tensor</li><li>grad：data的梯度</li><li>grad_fn：创建Tensor的Function，是自动求导的关键</li><li>requires_grad：指示是否需要梯度</li><li>is_leaf：指示是否是叶子结点</li></ul><h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><ul><li>dtype：张量的shujleixing</li><li>shape：张量的形状</li><li><p>device：张量所在的设备</p></li><li><p>data：被包装的Tensor</p></li><li>grad：data的梯度</li><li>grad_fn：创建Tensor的Function，是自动求导的关键</li><li>requires_grad：指示是否需要梯度</li><li>is_leaf：指示是否是叶子结点</li></ul><h3 id="张量的创建"><a href="#张量的创建" class="headerlink" title="张量的创建"></a>张量的创建</h3><h4 id="直接创建"><a href="#直接创建" class="headerlink" title="直接创建"></a>直接创建</h4><p><code>torch.tensor(data,dtype=None,device=None,requires_grad=Flase,pin_memory=False)</code></p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># ===============================  exmaple 1 ===============================# 通过torch.tensor创建张量## flag = Trueflag = Trueif flag:    arr = np.ones((3, 3))    print("ndarray的数据类型：", arr.dtype)    t = torch.tensor(arr, device='cuda')    # t = torch.tensor(arr)    print(t)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">ndarray的数据类型： float64tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]], device='cuda:0', dtype=torch.float64)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>data</td><td>数据，可以是list，numpy</td></tr><tr><td>dtype</td><td>数据类型，默认与data的一致</td></tr><tr><td>device</td><td>所在设备，cuda/cpu</td></tr><tr><td>requires_grad</td><td>是否需要梯度</td></tr><tr><td>pin_memory</td><td>是否存在锁页内存</td></tr></tbody></table></div><h4 id="张量的创建-1"><a href="#张量的创建-1" class="headerlink" title="张量的创建"></a>张量的创建</h4><pre class="line-numbers language-lang-python"><code class="language-lang-python"># ===============================  exmaple 2.数据增强方法 ===============================# 通过torch.from_numpy创建张量--两者共享内存# flag = Trueflag = Trueif flag:    arr = np.array([[1, 2, 3], [4, 5, 6]])    t = torch.from_numpy(arr)    print("numpy array: ", arr)    print("tensor : ", t)    print("\n修改arr")    arr[0, 0] = 0    print("numpy array: ", arr)    print("tensor : ", t)    print("\n修改tensor")    t[0, 0] = -1    print("numpy array: ", arr)    print("tensor : ", t)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">numpy array:  [[1 2 3] [4 5 6]]tensor :  tensor([[1, 2, 3],        [4, 5, 6]], dtype=torch.int32)修改arrnumpy array:  [[0 2 3] [4 5 6]]tensor :  tensor([[0, 2, 3],        [4, 5, 6]], dtype=torch.int32)修改tensornumpy array:  [[-1  2  3] [ 4  5  6]]tensor :  tensor([[-1,  2,  3],        [ 4,  5,  6]], dtype=torch.int32)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python知识点</title>
      <link href="/2020/02/25/python-zhi-shi-dian/"/>
      <url>/2020/02/25/python-zhi-shi-dian/</url>
      
        <content type="html"><![CDATA[<h2 id="工厂函数与内建函数"><a href="#工厂函数与内建函数" class="headerlink" title="工厂函数与内建函数"></a>工厂函数与内建函数</h2><ul><li><p><strong>内建函数</strong>，</p><p>一般都是因为==使用频繁或是元操作==，所以通过内置函数的形式提供出来，通过对python的内置函数分类分析可以看出来：基本的数据操作基本都是一些数学运算（当然除了加减乘除）、逻辑操作、集合操作、基本IO操作，然后就是对于语言自身的反射操作，还有就是字符串操作，也是比较常用的，尤其需要注意的是反射操作。</p></li><li><p><strong>工厂函数</strong></p><p>工厂函数都是==类对象==, 即当你调用他们时, 创建的其实是一个类实例</p></li><li><p><strong>内建方法</strong></p><p>内建类型的==成员方法==</p></li></ul><h2 id="单例模式与工厂模式"><a href="#单例模式与工厂模式" class="headerlink" title="单例模式与工厂模式"></a>单例模式与工厂模式</h2><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><ul><li><p>含义</p><p>确保某一个类中只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，单例模式是一种对象型模式，整个系统中只需要存在一个对象，所有的信息都从这个对象获取，比如系统的配置对象，或者是线程池。这些场景下，就非常适合使用单例模式。</p></li><li><p>设计理念</p><p>单例模式的实现只需要找一个变量存放创建的实例，然后每次获取实例时，先检查变量中是否已保存实例，如果没有则创建一个实例并将其存放到变量中，以后都从这个变量中获取实例就可以了。单例模式中，只会创建一次实例。</p></li><li><p>优点</p><p>由于单例模式的设计要求使得每一个应用、活动只有一个实例，这使得不管我们怎么去调用、实例化，当前唯一存在一个实例，这在资源调度、日志管理、信息注册等应用场景下保证了只有一个实例对其进行操作，而避免了多个实例同时操作一个对象，这保证了协调系统的整体性和统一性。</p></li><li><p>实现方法</p><ul><li>类中静态方法new()的实现</li><li>装饰器实现</li></ul></li><li><p>实现方法一的设计代码</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">class User(object):    __instance = None    def __new__(cls,name):        if not cls.__instance:            cls.__instance = object.__new__(cls)        return cls.__instance    def __init__(self,name):        self.name = name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>参考文章</p><ul><li><a href="https://zhuanlan.zhihu.com/p/87524388" target="_blank" rel="noopener">单例模式的妙用</a></li></ul></li></ul><h3 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h3><h4 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h4><ul><li><p>定义</p><p>简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。==在简单工厂模式中，可以根据参数的不同返回不同类的实例==。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。</p></li><li><p>结构</p><ul><li><p>Factory：工厂类</p></li><li><p>Product：抽象产品类</p></li><li><p>Concrete Product：具体产品类</p></li></ul></li><li><p>设计代码</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 抽象产品类class WeChat(object):    def send_message(self, content):        pass    def send_image(self, imageid):        pass# 具体产品类class AccountA(WeChat):    def send_message(self, content):        print("使用企业微信账号A推送信息: ", content)    def send_image(self, imageid):        print("使用企业微信账号A推送图片: ", imageid)class AccountB(WeChat):    def send_message(self, content):        print("使用企业微信账号B推送信息: ", content)    def send_image(self, imageid):        print("使用企业微信账号B推送图片: ", imageid)# 工厂类class WeChatFactory(object):    @staticmethod    # 增加账户需要修改此处代码，不否合开放封闭原则    def create_wechat(type):        if type=="A":            account=AccountA()            return account        elif type=="B":            account=AccountB()            return account        else:print("输入类型错误，没有此账户")# 使用者class Person(object):    def __init__(self,name):        self.name=name    def work(self,axe_type):        print("%s开始工作"%self.name)        #在原始社会，需要一把石斧        axe=Factory.create_axe(axe_type)        axe.Cut_tree()        #在现代社会，需要一把铁斧头if __name__ == "__main__":    # 实例化账号    wechat_factory = WeChatFactory()    # 创建账号A的微信对象    wechat1 = wechat_factory.create_wechat("A")    wechat2 = wechat_factory.create_wechat("A")    wechat3 = wechat_factory.create_wechat("A")    # 使用账号A对象发送信息    wechat1.send_message(content="haha")    wechat2.send_message(content="hehe")    wechat3.send_message(content="xixi")    # 创建账号B的微信对象    wechat4 = wechat_factory.create_wechat("B")    wechat5 = wechat_factory.create_wechat("B")    # 使用账号B对象发送信息    wechat4.send_message(content="heihei")    wechat5.send_message(content="pupu")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>简单工厂模式的优点</p><ul><li><p>工厂类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的责任，而仅仅“消费”产品；简单工厂模式通过这种做法实现了对责任的分割，它提供了专门的工厂类用于创建对象。</p></li><li><p>==客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量==。</p></li><li><p>通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。</p></li></ul></li><li><p>简单工厂模式的缺点</p><ul><li><p>由于工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。</p></li><li><p>使用简单工厂模式将会增加系统中类的个数，在一定程序上增加了系统的复杂度和理解难度。</p></li><li><p>==系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。==</p></li><li><p>简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。</p></li></ul></li><li><p>参考资料</p><ul><li><p><a href="https://blog.csdn.net/weixin_34233421/article/details/94607114" target="_blank" rel="noopener">python实现简单工厂模式</a></p></li><li><p><a href="https://www.jianshu.com/p/a1b97b93614e" target="_blank" rel="noopener">python实现工厂模式</a></p></li></ul></li></ul><h4 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h4><ul><li><p>定义</p><p>==定义一个接口来创建对象==，工厂本身并不负责创建对象，由子类完成 2、工厂方法的创建通过继承而不是实例化完成 3、工厂方法使得设计更加具有可定制性，返回相同的实例或子类，而不是某种类型的对象（类似简单工厂方法）</p></li><li><p>设计理念</p><ul><li>定义一个抽象的工厂接口类</li><li>定义一个抽象的产品接口类</li><li>根据需要从产品接口派生产品子类</li><li>对于每一个产品子类，从工厂接口派生工厂子类，负责该产品的创建</li><li>客户端根据实际需要，调用工厂子类，创建所需要的产品。</li></ul></li></ul><ul><li><p>设计代码</p><p>```python</p><h1 id="抽象产品类"><a href="#抽象产品类" class="headerlink" title="抽象产品类"></a>抽象产品类</h1><p>class WeChat:</p><pre><code>def send_message(self, content):    passdef send_image(self, imageid):    pass</code></pre><h1 id="具体产品类"><a href="#具体产品类" class="headerlink" title="具体产品类"></a>具体产品类</h1><p>class AccountA(WeChat):</p><pre><code>def send_message(self, content):    print("使用企业微信账号A推送信息: ", content)def send_image(self, imageid):    print("使用企业微信账号A推送图片: ", imageid)</code></pre></li></ul><p>  class AccountB(WeChat):</p><pre><code>  def send_message(self, content):      print("使用企业微信账号B推送信息: ", content)  def send_image(self, imageid):      print("使用企业微信账号B推送图片: ", imageid)</code></pre><h1 id="抽象工厂类"><a href="#抽象工厂类" class="headerlink" title="抽象工厂类"></a>抽象工厂类</h1><p>  class WeChatFactory:</p><pre><code>  def create_wechat(self):      pass</code></pre><h1 id="具体工厂类"><a href="#具体工厂类" class="headerlink" title="具体工厂类"></a>具体工厂类</h1><p>  class AccountAFactory(WeChatFactory):</p><pre><code>  def create_wechat(self):      return AccountA()</code></pre><p>  class AccountBFactory(WeChatFactory):</p><pre><code>  def create_wechat(self):      return AccountB()</code></pre><p>  if <strong>name</strong> == “<strong>main</strong>“:</p><pre><code>  # 实例化账号A  wechat_factory_a = AccountAFactory()  # 创建账号A的微信对象  wechat1 = wechat_factory_a.create_wechat()  wechat2 = wechat_factory_a.create_wechat()  wechat3 = wechat_factory_a.create_wechat()  # 使用账号A对象发送信息  wechat1.send_message(content="haha")  wechat2.send_message(content="hehe")  wechat3.send_message(content="xixi")  # 实例化账号B  wechat_factory_b = AccountBFactory()  # 创建账号B的微信对象  wechat4 = wechat_factory_b.create_wechat()  wechat5 = wechat_factory_b.create_wechat()  # 使用账号B对象发送信息  wechat4.send_message(content="heihei")  wechat5.send_message(content="pupu")</code></pre><h1 id="如果此时-两个微信账号都不够用了-需要增加第三个账号时-所有的类都不需要修改-只需创建新的类即可-符合开放封闭原则"><a href="#如果此时-两个微信账号都不够用了-需要增加第三个账号时-所有的类都不需要修改-只需创建新的类即可-符合开放封闭原则" class="headerlink" title="如果此时, 两个微信账号都不够用了, 需要增加第三个账号时, 所有的类都不需要修改, 只需创建新的类即可, 符合开放封闭原则"></a>如果此时, 两个微信账号都不够用了, 需要增加第三个账号时, 所有的类都不需要修改, 只需创建新的类即可, 符合开放封闭原则</h1><p>  class AccountC(WeChat):</p><pre><code>  def send_message(self, content):      print("使用企业微信账号C推送信息: ", content)  def send_image(self, imageid):      print("使用企业微信账号C推送图片: ", imageid)</code></pre><p>  class AccountCFactory(WeChatFactory):</p><pre><code>  def create_wechat(self):      return AccountC()</code></pre><pre><code>+ 工厂方法模式的优点  工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节 能够让工厂自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部 在系统中加入新产品时，完全符合开闭原则+ 工厂方法模式的缺点  系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，会给系统带来一些额外的开销 增加了系统的抽象性和理解难度+ 参考资料  + [Python语言实现工厂方法设计模式](https://www.jianshu.com/p/4e49f326169e)+ [python工厂方法模式](https://www.cnblogs.com/welan/p/9126922.html)  + [[python 设计模式之工厂模式 Factory Pattern (简单工厂模式，工厂方法模式，抽象工厂模式)](https://www.cnblogs.com/baxianhua/p/11648485.html)](https://www.cnblogs.com/baxianhua/p/11648485.html)  ### 抽象工厂模式+ 定义  + 提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。  + 对于同一系列的集中式生产，对于不同系列的分散式生产。  + 抽象工厂模式是所有形式的工厂模式中最为抽象和最具一般性的一种形式。当系统所提供的工厂生产的具体产品并不是一个简单的对象，而是多个==位于不同产品等级结构、属于不同类型的具体产品==时就可以使用抽象工厂模式 ，==抽象工厂模式中的具体工厂不只是创建一种产品，它负责创建一族产品== 当一个工厂等级结构可以创建出分属于不同产品等级结构的一个产品族中的所有对象时，抽象工厂模式比工厂方法模式更为简单、更有效率+ 设计代码  ```python  # ------1、第一步，先定义形状类这个系列------  import math  #定义一个“形状”的接口，里面定义一个面积的接口方法，只有方法的定义，并没有实现体  class IShape(object):       def Area(self):          pass  #定义4个图形类，都是实现Ishape接口，并且每一个图形都有一个可以计算面积的方法，相当于重写接口方法  class Circle(IShape):      def Area(self,radius):          return math.pow(radius,2)*math.pi  class Rectangle(IShape):      def Area(self,longth,width):          return 2*longth*width  class Triangle(IShape):      def Area(self,baselong,height):          return baselong*height/2  class Ellipse(IShape):      def Area(self,long_a,short_b):          return long_a*short_b*math.pi  # ------2、第二步，再定义颜色类这个系列------  #定义一个“颜色”的接口，里面定义一个颜色名称的接口方法，只有方法的定义，并没有实现体  class IColor(object):       def color(self):          pass  #定义3个颜色类，都是实现IColor接口，并且每一个图形都有一个可以获取颜色名称的方法，相当于重写接口方法  class Red(IColor):      def color(self,name):          print(f'我的颜色是：{name}')  class Blue(IColor):      def color(self,name):          print(f'我的颜色是：{name}')  class Black(IColor):      def color(self,name):          print(f'我的颜色是：{name}')  # ------3、第三步，定义抽象工厂以及与每一个系列对应的工厂------  class IFactory:  #模拟接口      def create_shape(self):  #定义接口的方法，只提供方法的声明，不提供方法的具体实现          pass      def create_color(self):          pass  #创建形状这一个系列的工厂  class ShapeFactory(IFactory): #模拟类型实现某一个接口，实际上是类的继承      def create_shape(self, name):  #重写接口中的方法          if name =='Circle':              return Circle()          elif name == 'Rectangle':              return Rectangle()          elif name == 'Triangle':              return Triangle()          elif name == 'Ellipse':              return Ellipse()          else:              return None  #创建颜色这一个系列的工厂  class ColorFactory(IFactory): #模拟类型实现某一个接口，实际上是类的继承      def create_color(self, name):  #重写接口中的方法          if name =='Red':              return Red()          elif name =='Blue':              return Blue()          elif name =='Black':              return Black()          else:              return None  # ------4、第四步，定义产生工厂类的类——抽象工厂模式的核心所在------  #定义一个专门产生工厂的类  class FactoryProducer:      def get_factory(self,name):          if name=='Shape':              return ShapeFactory()          elif name=='Color':              return ColorFactory()          else:              return None   if __name__=='__main__':      factory_producer=FactoryProducer()      shape_factory=factory_producer.get_factory('Shape')      color_factory=factory_producer.get_factory('Color')      #--------------------------------------------------------------      circle=shape_factory.create_shape('Circle')      circle_area=circle.Area(2)      print(f'这是一个圆，它的面积是：{circle_area}')      rectangle=shape_factory.create_shape('Rectangle')      rectangle_area=rectangle.Area(2,3)      print(f'这是一个长方形，它的面积是：{rectangle_area}')      triangle=shape_factory.create_shape('Triangle')      triangle_area=triangle.Area(2,3)      print(f'这是一个三角形，它的面积是：{triangle_area}')      ellipse=shape_factory.create_shape('Ellipse')      ellipse_area=ellipse.Area(3,2)      print(f'这是一个椭圆，它的面积是：{ellipse_area}')      #---------------------------------------------------------------      red=color_factory.create_color('Red')      red.color('红色')      blue=color_factory.create_color('Blue')      blue.color('蓝色')      black=color_factory.create_color('Black')      black.color('黑色')</code></pre><ul><li><p>抽象工厂模式的优点</p><ul><li>对于出现多系列的类型，创建逻辑清楚，因为是分门别类进行创建的；结合了“简单工厂模式”和“工厂方法模式”的优点</li><li>易于交换“产品系列”，只要更改相应的工厂即可。</li></ul></li><li><p>抽象工厂模式的缺点</p><ul><li>建立产品的时候很繁琐，需要增加和修改很多东西。<ul><li>需要再定义一个抽象接口，然后定义很多的类去实现这个接口</li><li>需要在抽象工厂接口中添加一个方法，并且还需要实现一个工厂类</li><li>需要更改超级工厂Factory Producer类</li></ul></li></ul></li><li><p>参考资料</p><ul><li><a href="https://blog.csdn.net/qq_27825451/article/details/84284681" target="_blank" rel="noopener">一文详解“抽象工厂模式”以及python语言的实现</a></li></ul></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性代数基础一</title>
      <link href="/2020/02/25/xian-xing-dai-shu-ji-chu-yi/"/>
      <url>/2020/02/25/xian-xing-dai-shu-ji-chu-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="basic-conception"><a href="#basic-conception" class="headerlink" title="basic conception"></a>basic conception</h1><h2 id="Zero-Matrix"><a href="#Zero-Matrix" class="headerlink" title="Zero Matrix"></a>Zero Matrix</h2><p>matrix with all zero entries, denoted by $O$ (any size) or $O_{m \times n}$</p><p>For example, a 2-by-3 zero matrix can be denoted</p><script type="math/tex; mode=display">O_{2 \times 3} = \left[\begin{matrix}  0 & 0 & 0\\  0 & 0 & 0 \\\end{matrix}\right]</script><h2 id="Identity-Matrix"><a href="#Identity-Matrix" class="headerlink" title="Identity Matrix"></a>Identity Matrix</h2><p> must be square,Sometimes $ I_n $  is simply written as $I$ (any size). </p><script type="math/tex; mode=display">I_3 = \left[\begin{matrix}  1 & 0 & 0\\  0 & 1 & 0 \\  0 & 0 & 1\end{matrix}\right]</script><h2 id="0-1-matrices"><a href="#0-1-matrices" class="headerlink" title="$(0,1)$ matrices"></a>$(0,1)$ matrices</h2><p>all the entities of A are zeros and ones called (0,1)matrices.</p><script type="math/tex; mode=display">I_3 = \left[\begin{matrix}  0&1 & 1 & 0\\  1 & 0 & 0&1 \\  1&0&0&0\\  0 & 1 & 0&0\end{matrix}\right]</script> <font color="red">get symmetirc matrix:$A^TA$</font>   <p>在生活中，我们会经常用到(0,1)矩阵(涉及图)</p><h2 id="Standard-Vectors"><a href="#Standard-Vectors" class="headerlink" title="Standard Vectors"></a>Standard Vectors</h2><p>we can write any vector $\left[<br>\begin{matrix}<br>  {a}\\<br>  {b}\\<br>\end{matrix}<br>\right]$in $R^2$ as a linear combination of the two vectors $\left[<br>\begin{matrix}<br>  {1}\\<br>  {0}\\<br>\end{matrix}<br>\right]$and$\left[<br>\begin{matrix}<br>  {0}\\<br>  {1}\\<br>\end{matrix}<br>\right]$</p><p>as follows:</p><script type="math/tex; mode=display">\left[\begin{matrix}  {a}\\  {b}\\\end{matrix}\right]=a\left[\begin{matrix}  {1}\\  {0}\\\end{matrix}\right]+b\left[\begin{matrix}  {0}\\  {1}\\\end{matrix}\right]</script><p>the vectors $\left[<br>\begin{matrix}<br>  {1}\\<br>  {0}\\<br>\end{matrix}<br>\right]$ and$\left[<br>\begin{matrix}<br>  {0}\\<br>  {1}\\<br>\end{matrix}<br>\right]$ are called the standard vectors of $R^2$ .</p><p>In general, we define the standard vectors of $R^n$ by</p><script type="math/tex; mode=display">e_1 =\left[\begin{matrix}  {1}\\  {0}\\  {\vdots}\\  {0}\end{matrix}\right]\qquad e_2 =\left[\begin{matrix}  {0}\\  {1}\\  {\vdots}\\  {0}\end{matrix}\right]\qquad \cdots \qquad e_n =\left[\begin{matrix}  {0}\\  {0}\\  {\vdots}\\  {1}\end{matrix}\right]</script><h2 id="Linear-Combination"><a href="#Linear-Combination" class="headerlink" title="Linear Combination"></a>Linear Combination</h2><ul><li>Given a vector set $\{u_1,u_2,\cdots,u_k\}$</li><li>The linear combination of the vectors in the set: <ul><li>$𝑣 = 𝑐1𝑢1 + 𝑐2𝑢2 + ⋯ + 𝑐𝑘𝑢𝑘$</li><li>$ 𝑐1, 𝑐2, ⋯ , 𝑐𝑘 $ are scalars (Coefficients of linear combination)</li></ul></li><li>the set of coefficients that express one vector as a linear combination of the others need not be unique</li><li>以线性方程组的思想理解线性组合</li></ul><script type="math/tex; mode=display">\begin{equation}  \left\{  \begin{array}{c}  a_{11}x_1+a_{12}x_{2}+...+a_{1n}x_{n} = b_{1} \\  a_{21}x_1+a_{22}x_{2}+...+a_{2n}x_{n} = b_{2} \\          \vdots\\  a_{m1}x_1+a_{m2}x_{n}+...+a_{mn}x_{n} = b_{n}  \end{array}\right.\end{equation}</script><script type="math/tex; mode=display">A =\left[\begin{matrix}  \mathbf{a_1}&\mathbf{a_2}&\mathbf{\cdots},\mathbf{a_n}\end{matrix}\right]</script><script type="math/tex; mode=display">x =\left[\begin{matrix}  {a_1}\\  {a_2}\\  {\vdots}\\  {a_n}\end{matrix}\right]\qquad coeffients</script><script type="math/tex; mode=display">\color{blue}{A}\color{red}{x} \color{black}=\color{red}{x_1}\color{blue}{a_1}\color{black}+\color{red}{x_2}\color{blue}{a_2}\color{black}+\color{red}{x_3}\color{blue}{a_3}\color{black}+\cdots\color{black}+\color{red}{x_n}\color{blue}{a_n}</script><p>$A{\color{red}{x}}=b$：b是向量集A的线性组合，x是系数集，若方程组有无数解，则x不唯一。</p><h2 id="Span"><a href="#Span" class="headerlink" title="Span"></a>Span</h2><ul><li>A vector set $S=\{u_1,u_2,{\cdots},u_k\}$ </li><li><p>Span of 𝑆 is the vector set of all linear combinations of $𝑢_1$, $𝑢_2$, ⋯ , $𝑢_k$ </p><ul><li><p>Denoted by 𝑆𝑝𝑎𝑛 $\{𝑢_1,𝑢_2, ⋯ ,𝑢_𝑘 \}$ or S𝑝𝑎𝑛  S</p></li><li><p>𝑆𝑝𝑎𝑛 𝑆 = $\{c_1u_1+c_2u_2+\cdots+c_ku_kfor\quad all |c_1,c_2,\cdots,c_k\}$ </p></li><li><p>Vector set $𝑉$ = 𝑆𝑝𝑎𝑛 $S$</p><ul><li>𝑆 is a generating set for 𝑉” or “𝑆 generates V” </li></ul></li></ul><ul><li>A vector set generated by another vector set is called <font color="red">Space </font></li></ul></li></ul><p><img src="/images/linear_algebra/span.png" alt="span" style="zoom:50%;"></p><ul><li>m independent vectors can span $R^m$ —-&gt;More than m vectors in $R^m $ must be dependent</li><li>m independent vectors can span $R^m$ —-&gt;More than m vectors in $R^m$  must be dependent</li></ul><h2 id="Dependent-and-Independent"><a href="#Dependent-and-Independent" class="headerlink" title="Dependent and Independent"></a>Dependent and Independent</h2><p>A set of n vectors $\{𝒂_1,𝒂_2,\cdots,𝒂_𝑛\}$ is linear dependent </p><ul><li><p>If there exist scalars 𝑥1, 𝑥2, ⋯ , 𝑥𝑛, <font color="red">not all zero</font>,</p></li><li><p>such that </p><script type="math/tex; mode=display">𝑥_1𝒂_1 + 𝑥_2𝒂_2 +\cdots+ 𝑥_𝑛𝒂_𝑛=0</script></li><li><p>A set of n vectors $\{𝒂_1, 𝒂_2,\cdots, 𝒂_𝑛\}$ is linear independent </p><script type="math/tex; mode=display">𝑥_1𝒂_1 + 𝑥_2𝒂_2 +\cdots+ 𝑥_𝑛𝒂_𝑛=0</script><p>Only if $𝑥1 = 𝑥2 = ⋯ = 𝑥𝑛 = 0$ </p></li></ul><font color="blue">Any set contains zero vector would be linear dependent</font> <h2 id="Reduced-row-echelon-form"><a href="#Reduced-row-echelon-form" class="headerlink" title="Reduced row echelon form"></a>Reduced row echelon form</h2><ul><li><p>Row Echelon Form</p><ul><li>Each nonzero row lies above every zero row（all its entries are 0）</li><li>The leading entries are in echelon form(阶梯型)</li></ul></li><li><p>reduced row echelon form</p><ul><li><p>The matrix is in row echelon form</p></li><li><p>The columns containing the leading entries are standard vectors</p><p><img src="/images/linear_algebra/ref.png" alt="ref" style="zoom:50%;"></p></li></ul></li><li><p>RREF在求解线性方程组中的应用</p><ul><li>一个线性方程组可以用增广矩阵来表示，对增广矩阵进行任何的基本行操作，解集不变</li><li>形如简化阶梯形矩阵可以很容器求出解集。<ul><li>当rref矩阵包含除最后一个元素非零的一行：无解</li><li>当rref矩阵的系数矩阵为单位矩阵：唯一解</li><li>其他情况：无穷解<ul><li>basic variables</li><li>free variables</li></ul></li></ul></li></ul></li><li><p>RREF的性质</p><ul><li>COLUMNS: If 𝒂𝒋 is a linear combination of other columns of A( with the same coefficients)&lt;—-&gt; 𝒓𝒋 is a linear combination of the corresponding columns of R with the same coefficients</li><li>ROWS: span$\{row_1,row_2,\cdots,row_n\}$ &lt;—-&gt;span$\{row^1,row^2,\cdots,row^n\}$ </li><li>The pivot columns are linear independent</li><li>The non-pivot columns are the linear combination of the previous pivot columns.</li></ul></li></ul><h2 id="Having-Solution-or-Not-of-system-of-linear-equations"><a href="#Having-Solution-or-Not-of-system-of-linear-equations" class="headerlink" title="Having Solution or Not of system of linear equations"></a>Having Solution or Not of system of linear equations</h2><ul><li>Is 𝑏 a linear combination of columns of 𝐴?</li><li>Is 𝑏 in the span of the columns of 𝐴?</li><li>is consistent?</li><li>is b in Col A?</li></ul><h2 id="How-many-solutions"><a href="#How-many-solutions" class="headerlink" title="How many solutions"></a>How many solutions</h2><ul><li><p>Columns of A are dependent &lt;—-&gt;If Ax=b have solution, it will have Infinite solutions</p></li><li><p>Columns of A are independent &lt;—-&gt;if Ax=b have solution ,it will have only one solution</p></li></ul><h2 id="Rank-and-Nullity"><a href="#Rank-and-Nullity" class="headerlink" title="Rank and Nullity"></a>Rank and Nullity</h2><ul><li>definition_1<ul><li>The rank of a matrix is defined as the maximum number of <font color="blue">linearly independent columns</font>&gt; in the matrix. </li><li>Nullity = <font color="red">Number of columns</font> - rank</li></ul></li><li>definition_2<ul><li>Rank=Number of Pivot Column</li></ul></li><li>definition_3<ul><li>Rank=Number of Non-zero rows</li></ul></li><li>definition_4<ul><li>Rank=Number of Basic Variables</li></ul></li><li>definition_5<ul><li>Rank= Dim (Col A): dimension of column space</li><li>Dimension of the range of A</li></ul></li><li>definition_6<ul><li>Rank=Dim(Row A): dimension of row space</li></ul></li><li>properties<ul><li>Rank $A$=n Nullity=0  &lt;—-&gt;   Columns of $A$ are independent</li><li>Given a $m\times n$ matrix $A$:$<ul><li>Matrix $A$ is full rank if Rank $A$ = min(m,n)</li><li>In $R^m$, you cannot find more than m vectors that are independent</li><li>rank $A$ = rank $A^T$  </li></ul></li></ul></li></ul><h2 id="Inverse-of-a-Matrix"><a href="#Inverse-of-a-Matrix" class="headerlink" title="Inverse of a Matrix"></a>Inverse of a Matrix</h2><ul><li><p>definition:</p><p>$A$ is called invertible if there is a matrix B such that $𝐴𝐵 = 𝐼$  and $𝐵𝐴 = I$ </p></li><li><p>elementary matrices</p><p>Every elementary row operation can be performed by matrix multiplication</p><ul><li><p>Interchange</p><script type="math/tex; mode=display">\color{blue}{\left[\begin{matrix} 0 & 1 \\ 1 & 0 \\\end{matrix}\right]}\color{black}{\left[\begin{matrix} a & b \\ c & d \\\end{matrix}\right]=\left[\begin{matrix} c & d \\ a & b \\\end{matrix}\right]}</script></li><li><p>Scaling</p><script type="math/tex; mode=display">\color{blue}{\left[\begin{matrix}  1 & 0 \\  0 & k \\\end{matrix}\right]}\color{black}{\left[\begin{matrix}  a & b \\  c & d \\\end{matrix}\right]=\left[\begin{matrix}  a & b \\  kc & kd \\\end{matrix}\right]}</script></li><li><p>Adding k times row i to row j</p><script type="math/tex; mode=display">\color{blue}{\left[\begin{matrix} 1 & 0 \\ k & 1 \\\end{matrix}\right]}\color{black}{\left[\begin{matrix} a & b \\ c & d \\\end{matrix}\right]=\left[\begin{matrix} a & b \\ ka+c & kb+d \\\end{matrix}\right]}</script></li></ul></li><li><p>Inverse of Elementary Matrix</p><p>Reverse elementary row operation</p></li></ul><script type="math/tex; mode=display">E_1=\left[\begin{matrix}  1 & 0 \\  k & 1 \\\end{matrix}\right]E_1^{-1}=\left[\begin{matrix}  1 & 0 \\  -k & 1 \\\end{matrix}\right]</script><ul><li><p>RREF &amp; Elementary Matrix</p><ul><li>Let A be an $m \times n$ matrix with reduced row echelon form R</li></ul><script type="math/tex; mode=display">𝐸_{𝑘}\cdots 𝐸_{2}𝐸_1𝐴 = R</script><ul><li>There exists an invertible m x m matrix P such that PA=R<script type="math/tex; mode=display">𝑃^{−1} = 𝐸_1^{−1}𝐸_2^{−1}\cdots 𝐸_𝑘^{−1}</script></li></ul></li><li><p>判断一个矩阵是否可逆</p><p>Let A be an n x n matrix. A is invertible if and only if</p><ul><li>The columns of $A$ span $R_n$</li><li>For every $b$  in $R_n$ , the system $Ax=b$  is consistent</li><li>The rank of $A$  is $n$ </li><li>The columns of $A$  are linear independent</li><li>The only solution to $Ax=0$  is the zero vector</li><li>The nullity of $A$  is zero</li><li>The reduced row echelon form of $A$ is $I_n$</li><li>$A$ is a product of elementary matrices</li><li>There exists an $n \times n$ matrix $B$ such that $BA = I_n$</li><li>There exists an $n \times n $ matrix $C$ such that $AC = I_n$ </li></ul></li></ul><h1 id="Subspace"><a href="#Subspace" class="headerlink" title="Subspace"></a>Subspace</h1><ul><li><p>definition</p><ul><li>The zero vector $0$  belongs to $V$ </li><li>If u and $w$  belong to $V$ , then $u+w$  belongs to $V$ (Closed under (vector) addition)</li><li>If u belongs to $V$ , and $c$  is a scalar, then $cu$  belongs to $V$ (Closed under scalar multiplication)</li></ul></li><li><p>special</p><p>zero subspace: the set $w$ consisting of only the zero vector in $R_n$ is a subspace of $R_n$ called the <strong>zero subspace</strong> . A subspace of $R_n$ other than ${0}$ is called a <strong>nonzero subspace</strong>.</p></li><li><p>properties</p><ul><li>The span of a vector set is a subspace</li><li>The <strong>null space</strong> of a matrix A is the solution set of Ax=0. It is denoted as Null A.</li><li>The <strong>column space</strong> of a matrix A is the span of its columns. it is denoted by Col A.</li><li><strong>Row space</strong> of a matrix A is the span of its rows. It is denoted as Row A. </li></ul></li></ul><h2 id="Basis"><a href="#Basis" class="headerlink" title="Basis"></a>Basis</h2><ul><li><p>definition</p><ul><li>Let $V$ be a nonzero subspace of $R_n$. A basis $B$ for $V$ is a linearly independent generation set of $V$ </li><li><p>$\{e_1,e_2,\cdots,e_n\}$ is a basis for $R_n$ </p><ul><li>$\{e_1,e_2,\cdots,e_n \}$ is independent</li><li>$\{e_1 , e_2 , \cdots, e_n \}$ generates $R$</li></ul></li><li><p>The pivot columns of a matrix form a basis for its columns space.</p></li></ul></li><li><p>properties</p><ul><li>$S$ is contained in Span $S$</li><li>If a finite set S’ is contained in Span $S$, then Span $S’$ is also contained in Span $S$</li><li>For any vector $z$, Span $S$ = Span $S∪{z}$ if and only if z belongs to the Span $ S$</li></ul></li><li><p>Theorem </p><ul><li><p>A basis is the <font color="blue">smallest generation set</font>.</p></li><li><p>A basis is the <font color="red">largest independent vector set</font> in the subspace.</p></li><li><p>Any two bases for a subspace <font color="green">contain the same number of vectors</font>.</p><ul><li>The number of vectors in a basis for a nonzero subspace V is called <font color="red">dimension</font> of $V $(<font color="red">dim</font> $V$).</li></ul></li></ul></li><li><p>Subspaces associated with a Matrix</p><p><img src="/images/linear_algebra/basis.png" alt="basis" style="zoom:50%;"></p></li></ul><h2 id="linear-transformations"><a href="#linear-transformations" class="headerlink" title="linear transformations"></a>linear transformations</h2><ul><li><p><strong>function</strong></p><p>let $S_1$ and $S_2$ be subsets of $R_n$ and $R_m$, respectively. A <strong>function</strong> $f$ from $S_1$ and $S_2$. written f :$S_1-&gt;S_2$. is a rule that assigns to each vector $v$ in $S_1$ A unique vector $f(v)$ in $S_2$ .The vector $f(v)$ is called the image of $v$ (under $f$). The set $S_1$ is called the <strong>domain</strong> of a function $f$. and the set $S_2$ is called the <strong>codomain</strong> of $f$. The $range$ of $f$ is defined to be the set of images $f(v)$ for all $v$ in $S_1$.</p><p><img src="/images/linear_algebra/T_a.jpg" alt="function" style="zoom:50%;"></p></li><li><p><strong>matrix transformation</strong></p><p><font color="blue">let A be an $m \times n$ matrix. The function $T_A:R^n -&gt;R^m$ defined by $T_A(X)=Ax$ for all $x$ in $R^n$ is called the <strong>matrix transformation</strong> induced by A</font>.</p><ul><li>rotations </li></ul><script type="math/tex; mode=display">A_0 = \left[\begin{matrix}  cos \theta & -sin \theta\\  sin \theta & cos \theta \end{matrix}\right]</script><ul><li><p>Expansion</p><script type="math/tex; mode=display">T_A = \left[\begin{matrix}  2 & 0 \\  0 & 2  \\\end{matrix}\right]</script></li><li><p>compression</p><script type="math/tex; mode=display">T_A = \left[\begin{matrix}  0.5 & 0 \\  0 & 0.5  \\\end{matrix}\right]</script></li><li><p>projections</p><p>将一个向量映射到$xy-plane$</p></li></ul><script type="math/tex; mode=display">T_A = \left[\begin{matrix}  1 & 0 & 0\\  0 & 1 & 0 \\  0 & 0 & 0\end{matrix}\right]</script><ul><li>shear</li></ul></li></ul><script type="math/tex; mode=display">T_A = \left[\begin{matrix}  1 & k \\  0 & 1  \\\end{matrix}\right]</script><p>​          </p><ul><li><p><strong>linear transformation</strong></p><p><font color="RED">A function T from $R^n$ to $R^m$. written $T: R^n -&gt;R^m$. is called linear transformation if for all vectors $u$ and $v$ in $R^n$ and all scalar c &lt;/FONT&gt;.</font></p><ul><li>$T(u+v) = T(u)+T(v)$</li><li>$T(cu) = cT(u)$</li></ul><p>special linear transformation</p><ul><li>matrix transformation</li><li>identity transformation</li><li>zero transformation</li></ul></li><li><p>standard matrix</p><p>let $T: R^n -&gt;R^m$ be a linear transformation. we call the $m \times n$ matrix </p><p>$A=[T(e_1) T(e_2)\cdots T(e_n)]$ </p><p>$T(v)=Av$ </p></li></ul><h2 id="coordinate-system"><a href="#coordinate-system" class="headerlink" title="coordinate system"></a>coordinate system</h2><ul><li><p>definition</p><ul><li><p>Let vector set $B=\{𝑢_1,𝑢_2, ⋯,𝑢_𝑛$ be a <strong><font color="red">basis</font></strong> for a subspace $R^n$ ,$B$ is a coordinate system</p></li><li><p>For any $v$ in $R^n$ , there are unique scalars $𝑐_1,𝑐_2,⋯,𝑐_𝑛$ such that $𝑣 = 𝑐_1𝑢_1 + 𝑐_2𝑢_2 + ⋯ + 𝑐_𝑛𝑢_n$ , <font color="red"><strong>$B$ -coordinate vector</strong></font> of $ v$:</p><script type="math/tex; mode=display">[v]_B =\left[\begin{matrix}  {c_1}\\  {c_2}\\  {\vdots}\\  {c_n}\end{matrix}\right]\in R^n</script></li></ul></li></ul><p><img src="/images/linear_algebra/coordinate.png" alt="coordinate system" style="zoom:50%;"></p><h2 id="Linear-Function-in-Coordinate-System"><a href="#Linear-Function-in-Coordinate-System" class="headerlink" title="Linear Function in Coordinate System"></a>Linear Function in Coordinate System</h2><p><img src="/images/linear_algebra/linear_opertor.png" alt="linear_opertor" style="zoom:50%;"></p><p><img src="/images/linear_algebra/matirx_representation.png" alt="matirx_representation" style="zoom:50%;"></p><h1 id="EIGENVALUES-EIGENVECTORS"><a href="#EIGENVALUES-EIGENVECTORS" class="headerlink" title="EIGENVALUES, EIGENVECTORS"></a>EIGENVALUES, EIGENVECTORS</h1><h2 id="Eigenvalues-and-Eigenvectors"><a href="#Eigenvalues-and-Eigenvectors" class="headerlink" title="Eigenvalues and Eigenvectors"></a>Eigenvalues and Eigenvectors</h2><ul><li><p>definition</p><p>If $𝐴𝑣 = 𝜆𝑣$ ($𝑣$ is a vector, $𝜆$ is a scalar)</p><ul><li>$𝑣$ is an eigenvector of $A$(excluding zero vector)</li><li>$𝜆$ is an eigenvalue of $A$ that corresponds to $v$</li></ul></li><li><p>properties</p><ul><li>An eigenvector of A corresponds to a unique eigenvalue</li><li>An eigenvalue of A has infinitely many eigenvectors</li></ul></li><li><p>eigenspace</p><p>$𝑁𝑢𝑙𝑙(A − \lambda I_n )$</p></li><li><p>how to look for the eigenvalue</p><p>$det(A-tI_n)=0$ characteristic equation</p><p>$det(A-tI_n)$ characteristic polynomial</p><p><strong>Eigenvalues are the roots of characteristic polynomial or solutions of characteristic equation</strong></p></li></ul><h2 id="Characteristic-Polynomial"><a href="#Characteristic-Polynomial" class="headerlink" title="Characteristic Polynomial"></a>Characteristic Polynomial</h2><ul><li><p>definition</p><p>Characteristic polynomial of A is</p></li></ul><script type="math/tex; mode=display">det(A-tI_n)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\cdots(t-\lambda_k)^{m_k}(\cdots)</script><p>​    $m_k \text{ is call the multiplicity of }\lambda$  </p><p>An n x n matrix A have less than or equal to n eigenvalues</p><ul><li><p>properties</p><p>let $\lambda$ be an eigenvalue of a matrix A .the dimension of the eigenspace of $A$ corresponding to $\lambda$  is less than or equal to the multiplicity of $\lambda$.</p></li></ul><h2 id="The-eigenvalues-of-similar-matrices"><a href="#The-eigenvalues-of-similar-matrices" class="headerlink" title="The eigenvalues of similar matrices"></a>The eigenvalues of similar matrices</h2><p>Similar matrices have the same characteristic polynomials</p><p>The same Eigenvalues</p><p>$det(A-tI_n)=det(B-tI_n)|B=P^{-1}AP$</p><ul><li><p>definition</p><p>two matrices $A$ and $B$ are called similar if there exists an invertible matrix $P$ SUCH THAT $B=P^{-1}AP$</p></li><li><p>properties</p><p>similar matrices have the same characteristic polynomial  and hence hence the same eigenvalues and multiplicities. In addition, their eigenspaces corresponding to the same eigenvalue have the same dimension.</p></li></ul><h2 id="Diagonalization"><a href="#Diagonalization" class="headerlink" title="Diagonalization"></a>Diagonalization</h2><ul><li><p>definition</p><p> An $n\times n$ matrix$ A$ is called diagonalizable if $𝐴 = 𝑃𝐷𝑃^{-1}$1</p><ul><li><p>$D$: $n\times n$ diagonal matrix</p></li><li><p>$P$: $ n\times n$ invertible matrix</p><script type="math/tex; mode=display">P= \left[\begin{matrix}  p_1 & \cdots &p_n \\\end{matrix}\right]</script><script type="math/tex; mode=display">D = \left[\begin{matrix}  d_1 & \cdots & 0 \\  \vdots &\ddots  &\vdots  \\  0 &\cdots &d_n\end{matrix}\right]</script></li></ul></li></ul><script type="math/tex; mode=display">𝐴 = 𝑃𝐷𝑃^{-1}->Ap_i=d_ip_i \\p_i \text{ is an eigenvector of A corresponding to eigenvalue }d_i</script><ul><li><p>properties</p><p>There are n eigenvectors that form an invertible matrix</p><p>There are n independent eigenvectors</p><p>The eigenvectors of A can form a basis for $R^n$ .</p></li><li><p>how to diagonalize a matrix A?</p><ul><li>Find n eigenvectors corresponding if possible, and form an invertible P</li><li>The eigenvalues corresponding to the eigenvectors in P form the diagonal matrix D</li></ul><p><img src="/images/linear_algebra/diagonalization.png" alt="diagonalization" style="zoom:50%;"></p></li></ul><p><img src="/images/linear_algebra/diagonalizable2.png" alt="diagonalization" style="zoom:50%;"></p><ul><li><p>When is a matrix diagonalizable?</p><p>An n x n matrix A is diagonalizable if and only if both the following conditions are met</p><ul><li>The characteristic polynomial of $A$ factors into a product of linear factors.<script type="math/tex; mode=display">det(A-tI_n)=(t-\lambda_1)^{m_1}(t-\lambda_2)^{m_2}\cdots(t-\lambda_k)^{m_k}(\cdots)</script></li></ul></li><li><p>For each eigenvalue $\lambda$ of $A$, the multiplicity of $\lambda$ equals the dimension of the corresponding eigenspace.</p></li></ul><p><img src="/images/linear_algebra/diagonalizable3.png" alt="diagonalizable3" style="zoom:50%;"></p><h1 id="Orthogonality"><a href="#Orthogonality" class="headerlink" title="Orthogonality"></a>Orthogonality</h1><h2 id="basic-concept"><a href="#basic-concept" class="headerlink" title="basic concept"></a>basic concept</h2><ul><li><p>Norm</p><p> Norm of vector v is the length of v</p></li></ul><script type="math/tex; mode=display">\Vert v\Vert=\sqrt(v_1^2+v_2^2+\cdots+v_n^2)</script><ul><li><p>Distance</p><p>The distance between two vectors u and v is defined by $\Vert v-u \Vert$</p></li><li><p>Dot product</p><p> dot product of u and v is</p><script type="math/tex; mode=display">u \cdot v=u_1v_1+u_2v_2+\cdots+u_nv_n \\=\left[\begin{matrix}  u_1 & u_2&\cdots &u_n \\\end{matrix}\right]\left[\begin{matrix}  {v_1}\\  {v_2}\\  {\vdots}\\  {v_n}\end{matrix}\right]=u^Tv</script></li></ul><h2 id="Orthogonal"><a href="#Orthogonal" class="headerlink" title="Orthogonal"></a>Orthogonal</h2><ul><li><p>definition</p><p>u and v are orthogonal if $𝑢 \cdot 𝑣 = 0$</p></li><li><p>Pythagorean Theorem</p><script type="math/tex; mode=display">\Vert u+v\Vert^2=\Vert u\Vert^2+\Vert v\Vert^2</script></li><li><p>Triangle Inequality</p><script type="math/tex; mode=display">\Vert u+v\Vert^2 \le\Vert u\Vert^2+\Vert v\Vert^2</script></li></ul><h2 id="Orthogonal-Basis"><a href="#Orthogonal-Basis" class="headerlink" title="Orthogonal Basis"></a>Orthogonal Basis</h2><ul><li><p>Orthogonal Set</p><ul><li>A set of vectors is called an orthogonal set if every pair of distinct vectors in the set is orthogonal.</li><li>Any orthogonal set of <font color="red">nonzero</font> vectors is linearly independent.</li></ul></li><li><p>Orthonormal Set</p></li><li><p>A set of vectors is called an orthonormal set if it is an orthogonal set, and the norm of all the vectors is 1</p></li><li><p>Orthogonal Basis</p><ul><li><p>A basis that is an orthogonal (orthonormal) set is called an orthogonal (orthonormal) basis</p></li><li><p>Let $𝑆 = 𝑣_1, 𝑣_2,\cdots,𝑣_𝑘$ be an orthogonal basis for a subspace $W$, and let $u $be a vector in $W$.</p><script type="math/tex; mode=display">u=c_1v_1+c_2v_2+\cdots+c_kv_k \\c_1=\frac{u \cdot v_1}{\Vert v_1 \Vert^2} \\c_2=\frac{u \cdot v_2}{\Vert v_2 \Vert^2}\\c_n=\frac{u \cdot v_n}{\Vert v_n \Vert^2}</script></li><li><p>Let 𝑢1, 𝑢2, ⋯ , 𝑢𝑘 be a basis of a subspace V. How to transform 𝑢1, 𝑢2, ⋯ , 𝑢𝑘 into an orthogonal basis 𝑣1, 𝑣2, ⋯ , 𝑣𝑘 ?</p><p><img src="/images/linear_algebra/rothogonal_basis.png" alt="rothogonal_basis" style="zoom:50%;"></p></li></ul></li></ul><h2 id="Orthogonal-complement（正交补空间）"><a href="#Orthogonal-complement（正交补空间）" class="headerlink" title="Orthogonal complement（正交补空间）"></a>Orthogonal complement（正交补空间）</h2><ul><li>orthogonal complement<ul><li>The orthogonal complement of a nonempty subset $S$ of $R^n$ denoted by $S^{\perp}$ , is the set of all vector in $R^n$ that are orthogonal to every vector in S. that is </li><li>The orthogonal complement of any nonempty subset of $R^n$ is a subspace of  $R^n$</li></ul></li></ul><script type="math/tex; mode=display">S^{\perp}=\{v \in R^n:v \cdot u=0 \text{ for every }u \text{ in } S\}</script><h2 id="Orthogonal-Decomposition-Theorem"><a href="#Orthogonal-Decomposition-Theorem" class="headerlink" title="Orthogonal Decomposition Theorem"></a>Orthogonal Decomposition Theorem</h2><ul><li><p>let $W$ be a subspace of $R^n$ .Then, for any vector $u$ in $R^n$ .there exist unique vector $w$ in $W$ and $z$ in $W^{\perp}$ </p><p>such that $u=w+z$ .In addition, if $\{v_1,v_2,\cdots,v_K\}$ is an orthonormal basis for $W$ </p><script type="math/tex; mode=display"></script></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 线性代数 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线性代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>transH</title>
      <link href="/2020/01/28/transh/"/>
      <url>/2020/01/28/transh/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们处理将由实体和关系组成的大规模知识图谱嵌入到连续向量空间中的问题。TransE是一种有效的嵌入方法。但是 ，TranE方法适用于一对一关系，在处理自反，一对多，多对一和多对多的关系上做的并不好；同时，一些复杂的模型能够很好的处理这些复杂关系，但是效率低下，为了平衡模型容量和效率，提出了TransH。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>分析TransE在自反/一对多/多对一/多对多关系上的问题</li><li>提出TransH解决方法</li><li>如何构建负例以减少训练中的虚假负例</li></ul><h2 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h2><p>$h$：head entity</p><p>$r$ ：relation</p><p>$t$ ：tail entity</p><p>$\textbf{h},\textbf{r},\textbf{t}$ ：连续空间内的向量</p><p>$\Delta$ :：组集合</p><p>$\Delta^{’}$ ：错误三元组集合</p><p>$E$ ：实体集合</p><p>$R$ ：关系集合</p><h2 id="TransE算法存在的问题"><a href="#TransE算法存在的问题" class="headerlink" title="TransE算法存在的问题"></a>TransE算法存在的问题</h2><ul><li>transE模型的两个结论<ul><li>如果$(h,r,t)∈Δ$ and $(t,r,h)\in\Delta$ ,即 关系$r$ 是一个自反的映射，那么可以知道$\textbf{r=0}$ 并且$\textbf{h}=\textbf{t}$ </li><li>如果$\forall_i\in\{0,1,2,\cdots,m\},(h_i,r,t)\in\Delta$ ,也就是说r是一个多对一的映射，那么$\textbf{h}_0=\textbf{h}_1=\textbf{h}_2=\cdots=\textbf{h}_m$ .同理，对于$\forall_i,(h,r,t_i)\in\Delta$是一个多对一的映射，那么可以知道$\textbf{t}_0=\textbf{t}_1=\textbf{t}_2=\cdots=\textbf{t}_n$ </li></ul></li><li>从上述结果可以发现，transE算法在处理自反关系，以及多对一、一对多、多对多关系中，会使得一些不同的实体具有相同或者相似的向量。其根本原因在于，<strong>出现在多个关系中的同一个实体的表示是相同的</strong>。</li><li>问题举例<ul><li>(美国，总统，奥巴马)，（美国，总统，布什），在TransE中，奥巴马和布什表示为相似向量</li></ul></li></ul><h2 id="tranH"><a href="#tranH" class="headerlink" title="tranH"></a>tranH</h2><ul><li><p>核心思想</p><p>每一个关系定义一个超平面${W}_r$ ,和一个关系向量$\textbf{d}_r$ 。$\textbf{h}_{\bot},\textbf{t}_{\bot}$是$h$，$t$在$W_r$ 上的投影向量，我们希望正确的三元组满足$\textbf{h}_{\bot}+\textbf{d}_r=\textbf{t}_{\bot}$ 。<strong>这样能够使得同一实体在不同关系中的意义不同，同时不同实体，在同一关系中的意义，也可以相同。</strong><br><img src="/images/transH/1.png" alt="TransH" style="zoom:50%;"></p></li><li><p>得分函数</p><script type="math/tex; mode=display">d(\textbf{h}+\textbf{r},\textbf{t})=f_r(\textbf{h},\textbf{t})=\lVert \textbf{h}_{\bot}+\textbf{d}_r-\textbf{t}_{\bot}\rVert_2^2</script></li></ul><p>  对于平面${W}_r$ 我们可以使用法向量来表示，我们不妨假设$\textbf{w}_r$ 为平面$W_r$ 的法向量，并加约束条件$\lVert \textbf{w}_r\rVert_2^2=1$,所以我们知道$\textbf{h}$在$\textbf{w}_r$ 上的投影为</p><script type="math/tex; mode=display">  \textbf{h}_{\textbf{w}_r}=\textbf{w}^T\textbf{h}\textbf{w} (\textbf{w} \cdot \textbf{h}=\textbf{w}^T\textbf{h})</script><p>  这是因为$|w_r||h|cos\theta$ 表示h在w方向上投影的长度，再乘以$w_r$即为$h$在$w_r$上的投影向量，所以得出</p><script type="math/tex; mode=display">  f_r(\textbf{h},\textbf{t})=\lVert \textbf{h}_{\bot}+\textbf{d}_r-\textbf{t}_{\bot}\rVert_2^2=\lVert \textbf{h}-\textbf{h}_{\textbf{w}_r}+\textbf{d}_r-(\textbf{t}-\textbf{t}_{\textbf{w}_r})\rVert_2^2=\lVert \textbf{h}-\textbf{w}^T\textbf{h}\textbf{w}+\textbf{d}_r-(\textbf{t}-\textbf{w}^T\textbf{t}\textbf{w})\rVert_2^2</script><p><img src="/images/transH/2.png" alt="TransH" style="zoom:50%;"></p><ul><li>代价函数</li></ul><script type="math/tex; mode=display">L=\sum_{(h,r,t)\in\Delta}\sum_{(h^{'},r^{'},t^{'})\in \Delta}[f_r(\textbf{h},\textbf{t})+\gamma+f_{r^{'}}(\textbf{h}^{'},\textbf{t}^{'})]_+</script><p>在公式中，$[x]_+\triangleq max(x,0)$ </p><ul><li><p>训练的限制条件</p><ul><li>$\forall e\in E, ||{\bf e}||_2 \leq 1$ , # 控制实体嵌入大小</li><li>$\forall r \in R, \frac{|{\bf w}_t^T {\bf d}_r|}{||{\bf d}_r||_2} \leq \epsilon$ , # 正交，控制转移向量落在超平面</li><li>$\forall r \in R. ||{\bf w}_r||_2=1$ , # 单位法向量</li></ul></li><li><p>无约束代价函数</p><script type="math/tex; mode=display">L=\sum_{(h,r,t)\in\Delta}\sum_{(h^{'},r^{'},t^{'})\in \Delta}[f_r(\textbf{h},\textbf{t})+\gamma+f_{r^{'}}(\textbf{h}^{'},\textbf{t}^{'})]_+ + \{\sum_{e\in E}[||{\bf e}||_2^2 -1]_+ + \sum_{r \in R}left[\frac{({\bf w}_t^T {\bf d}_r)^2}{||{\bf d}_r||_2^2} - \epsilon ^2 ]_+ \}</script></li></ul><ul><li>C是软约束的超参数权重</li><li>注意到约束3不在loss公式里，在访问每一个mini-batch时将每一个${bf w}_r$投影到单位 <a href="https://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">$L_2-\bf {ball}$</a>。</li></ul><h2 id="负样本构造"><a href="#负样本构造" class="headerlink" title="负样本构造"></a>负样本构造</h2><p>在本篇论文中除了提出了TranH模型，另一贡献是提出了基于伯努利分布的采样方法。在原来的均匀采样中，容易将错误的负例引入到训练过程中来，例如，对于正例（美国，总统，奥巴马），随机替换奥巴马为罗斯福构成（美国，总统，罗斯福）作为负例，实际上由于罗斯福也是总统，这并不是一个负例。新的采样方法的动机是，对于一对多关系，我们以更大的概率来替换其头实体，对于多对一关系，我们以更大的概率来替换其尾实体。</p><p>相对于TransE模型的随机采样生成负样本，TransH模型的创新点：<br><strong>赋予头尾实体采样概率</strong></p><ul><li>处理1-N关系时，赋予头部实体更高的采样概率；</li><li>处理N-1关系时，赋予尾部实体更高的采样概率；</li></ul><p>在所有关系r的三元组中，首先获取两个数据：</p><ul><li>$tph$: 每一个头部实体对应的平均尾部实体;</li><li>$hpt$: 每一个尾部实体对应的平均头部实体;</li></ul><p>针对这两个数据进行映射的分类：</p><script type="math/tex; mode=display">\left[\begin{array}{rcl}1-1 & \mbox{for} & tph_r<1.5,hpt_r <1.5\\N-N & \mbox{for} & tph_r \geq 1.5,hpt_r \geq 1.5\\1-N & \mbox{for} & tph_r \geq 1.5,hpt_r < 1.5\\N-1 & \mbox{for} & tph_r < 1.5,hpt_r \geq 1.5\\\end{array}\right]</script><p>定义一个伯努利分布进行采样：</p><ul><li>$\frac{tph}{tph+hpt}$: 采样头部实体的概率;</li><li>$\frac{hpt}{tph+hpt}$: 采样尾部实体的概率;</li></ul><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>在三个任务上研究评估模型：从不同视角和应用层面，评估对陌生三元组的预测精度</p><ul><li>link prediction</li><li>triplets classification</li><li>relational fact extraction</li></ul><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h4 id="link-prediction"><a href="#link-prediction" class="headerlink" title="link prediction"></a>link prediction</h4><ul><li><p><strong>任务</strong></p><p>三元组的头部或者尾部实体缺失，给定 $(h,r)$ 预测 $t$ 或者给定 $(r,t)$ 预测 $h$ , 返回预测的候选排名；</p></li><li><p><strong>评估协议</strong></p><p>对于给定的三元组，用每个实体 $e$ 取代尾部实体 $t$ ，并计算损坏样本的差异性分数，升序排列获取原始三元组的排名；</p></li><li><p><strong>过滤</strong></p></li></ul><p>生成的负例三元组可能原本就存在于知识图谱中，需要删去；</p><ul><li><strong>报告指标</strong>：<ul><li>Mean:平均排名:</li><li>$Hits@10$: 排名不超过10的比例</li></ul></li></ul><h4 id="triplets-classification"><a href="#triplets-classification" class="headerlink" title="triplets classification"></a>triplets classification</h4><p><strong>任务</strong>: 对给定三元组进行二分类判断正负样本；</p><h4 id="relational-fact-extraction"><a href="#relational-fact-extraction" class="headerlink" title="relational fact extraction"></a>relational fact extraction</h4><p>(待补充)</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> KG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Trans系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cuda_knowledge</title>
      <link href="/2020/01/20/cuda-knowledge/"/>
      <url>/2020/01/20/cuda-knowledge/</url>
      
        <content type="html"><![CDATA[<h2 id="cuda的相关操作"><a href="#cuda的相关操作" class="headerlink" title="cuda的相关操作"></a>cuda的相关操作</h2><ol><li><p>查看驱动（drive cuda）版本</p><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">nvidia-smi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令还可以实时显示GPU的使用情况</p><pre class="line-numbers language-lang-bash"><code class="language-lang-bash">watch -n 1 nvidia-smi  #一秒刷新一次<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>查看cuda toolkit的版本</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">nvcc --version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h2 id="不错的参考资料"><a href="#不错的参考资料" class="headerlink" title="不错的参考资料"></a>不错的参考资料</h2><p><a href="https://www.cnblogs.com/yhjoker/p/10972795.html" target="_blank" rel="noopener">Pytorch 使用不同版本的cuda</a></p><p><a href="https://www.cnblogs.com/marsggbo/p/11838823.html" target="_blank" rel="noopener">显卡，显卡驱动，nvcc,cuda概念的介绍</a></p><p><a href="https://www.jianshu.com/p/9f89633bad57" target="_blank" rel="noopener">安装详解</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> GPU </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cuda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>link prediction</title>
      <link href="/2020/01/15/link-prediction/"/>
      <url>/2020/01/15/link-prediction/</url>
      
        <content type="html"><![CDATA[<h2 id="链路预测的背景"><a href="#链路预测的背景" class="headerlink" title="链路预测的背景"></a>链路预测的背景</h2><p>通常来说，KB以三元组 (h, r, t) 的集合的形式呈现，其中 h是头实体，t是尾实体，而r是关系。例如，（巴黎，是首都，法国）就是一个知识三元组。尽管现存的KB包含了很多这样的信息，但众所周知，KB中仍有大量的知识缺失。这催生了大量关于“知识图谱补全（Knowledge Base Completion）”任务的研究，该任务旨在基于现有的KB的内容来填充缺失的知识，而最常见的情况是，知识图谱补全以链接预测的形式来实现。</p><h2 id="链路预测的任务"><a href="#链路预测的任务" class="headerlink" title="链路预测的任务"></a>链路预测的任务</h2><p>链接预测任务预测<font color="red">未在</font>知识图谱中出现的三元组成立的可能性，是对知识图谱进行补全的有效方式，其==核心思想是基于知识图谱中的已知事实对未在知识图谱中出现的三元组的合理性进行评估，选取合理性较高的事实加入知识图谱对原有知识进行补全从而提高知识图谱的质量==。</p><p>知识图谱上的链接预测目的是为了能够预测出一个三元组（h，r，t）缺失的头实体h，尾实体t或者关系r</p><h2 id="链路预测方法"><a href="#链路预测方法" class="headerlink" title="链路预测方法"></a>链路预测方法</h2><ul><li><p><strong><em>基于表示的链接预测方法</em></strong>：对知识图谱中的实体和关系进行合适的表示，拟合一个函数f，函数的输入为三元组中两个实体和其关系的表示（也有部分模型的输入还包含在知识图谱中将两个实体关联起来的路径），输出为该三元组(s, r, o)的评分，将评分视为该三元组成立的置信度，从而完成链接预测。基于表示的链接预测方法大部分依赖知识图谱嵌入(Knowledge Graph Embedding, KGE)的技术，KGE将知识图谱中的实体和关系表示为低维的连续向量，在保留知识图谱结构信息的同时简化知识图谱上的操作。</p><p>基于表示的链接预测方法大部分依赖知识图谱嵌入(Knowledge Graph Embedding, KGE)[3]的技术，KGE将知识图谱中的实体和关系表示为低维的连续向量，在保留知识图谱结构信息的同时简化知识图谱上的操作。</p><p>KGE一般包含三步：1.确定实体和关系的表示方法；2.定义评分函数衡量三元组(s, r, o)的合理性；3.训练模型，最大化知识图谱中正例的评分函数，学习实体和关系的表示。使用KGE模型进行链接预测时选择合理性较高的三元组作为预测得到的事实。</p><ul><li><p><strong>翻译距离模型</strong>(Translational Distance Models)</p><p>此类模型基于距离的评分函数构建。对于三元组(s, r, o)，测量经过关系r进行转换后两个实体s和o之间的距离，距离越小该三元组成立的可能性越高。在训练过程中应使训练数据中正例实体间距离较小，负例实体间的距离较大。此类方法研究很多，以TransE 为代表，改变关系转换方式、距离测量方式和实体表示方式可以衍生出多种不同的具体算法，例如TransH，TransR等。-</p></li><li><p>语义匹配模型(Semantic Matching Models)</p><p>语义匹配模型基于相似性评分函数，通过匹配实体和关系的潜在语义衡量事实的合理性，常见的方法有两大类：</p><ul><li>基于张量分解的方法</li><li>基于深度神经网络的方法</li></ul></li></ul></li><li><p>基于规则的链接预测方法：在知识图谱中的已知事实中挖掘通用的规则，得到一组规则以及每条规则相对应的置信度，对于每个查询的三元组(s, r, o)，将其与规则集合中的规则进行匹配，集成匹配结果得到三元组的置信度，从而完成链接预测。</p><p>基于规则的链接预测的研究主要关注如何评估规则的置信度，如何设置合理的假设空间，如何构建有效的在启发式策略在庞大的假设空间中高效搜索，如何设置合适的筛选条件进行剪枝操作。</p></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><p>微信公众号openKE：浅谈知识图谱中的链接预测</p></li><li><p><a href="http://www.doc88.com/p-3804861825877.html" target="_blank" rel="noopener">基于位置的知识图谱连接预测</a></p></li><li><p><a href="https://blog.csdn.net/tgqdt3ggamdkhaslzv/article/details/97196258" target="_blank" rel="noopener">基于层次约束的链接预测</a></p></li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> KG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KRL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>matplotplit_note</title>
      <link href="/2019/12/21/matplotlib-note/"/>
      <url>/2019/12/21/matplotlib-note/</url>
      
        <content type="html"><![CDATA[<h1 id="Matplotlib学习笔记"><a href="#Matplotlib学习笔记" class="headerlink" title="Matplotlib学习笔记"></a>Matplotlib学习笔记</h1><h2 id="一-基础知识"><a href="#一-基础知识" class="headerlink" title="一. 基础知识"></a>一. 基础知识</h2><h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h3><p>通过散点图探究数据之间的相关问题（正相关，负相关，不相关）</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as npimport matplotlib.pyplot as pltN = 1000x = np.random.randn(N)y = np.random.randn(N)plt.scatter(x, y, c="r", marker="o", alpha=0.5)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/scatter.png" alt="散点图"></p><p>scatter(x, y, s, c, market)函数详解</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>x</td><td>array_like</td></tr><tr><td>y</td><td>array_like</td></tr><tr><td>s</td><td>点的面积，</td></tr><tr><td>c</td><td>点的颜色</td></tr><tr><td>marker</td><td>点的形状（在官方文档搜索”markers”）</td></tr><tr><td>alpha</td><td>点的透明度（0-1，重叠的点颜色加深）</td></tr></tbody></table></div><h3 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h3><p>通过折线图观察数据的变化趋势（主要是数据随时间的变化图）</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-10, 10, 10)y = x**2plt.plot(x, y, "go--", linewidth=2, markersize=3)plt.plot(x, y*2, color="green", linestyle="--", marker="o")plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8"""数据随时间的变化"""import numpy as npimport matplotlib.pyplot as pltimport matplotlib.dates as mdateimport datetimefig = plt.figure()ax = plt.gca()  # 获取当前的轴start = datetime.datetime(2019, 12, 1)  # 开始日期close = datetime.datetime(2019, 12, 21)  # 结束日期delta = datetime.timedelta(days=1)  # 时间间隔dates = mdate.drange(start, close, delta)  # 生成日期序列values = np.random.rand(len(dates))   # 模拟数据变化date_format=mdate.DateFormatter('%Y/%m/%d')ax.xaxis.set_major_formatter(date_format)  # 设置主定位器为日期格式fig.autofmt_xdate()  # 自动调整日期显示位置，避免日期之间相互重叠plt.plot_date(dates, values, "b-")  # 绘图plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/carve.png" alt="折线图"></p><p><img src="/images/matplotplit-notes/carve_time.png" alt="时间折线图"></p><p>plot([x], y, [fmt], [x2], y2, [fmt2],linewidth, markersize, label )</p><p>plot(x, y, color, marker, linestyle, linewidth, matkersize, label)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>x</td><td>array-like,<em>x</em> values are optional and default to `range(len(y))</td></tr><tr><td>y</td><td>array-like</td></tr><tr><td>fmt</td><td>定义基本的格式，如颜色，标记，线型</td></tr><tr><td>color</td><td>颜色</td></tr><tr><td>linewidth</td><td>线型宽度</td></tr><tr><td>linestyle</td><td>线型</td></tr><tr><td>markersize</td><td>标记大小</td></tr><tr><td>label</td><td>线条名称，用于图例</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>列表</td><td>列表中的元素是a <span style="color:red">line</span> of <code>.Line2D</code> objects representing the plotted data</td></tr></tbody></table></div><h3 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltN = 5y = [20, 10, 30, 25, 15]index = np.arange(5)plt.bar(index, y, width=0.3, bottom=0, align="edge", edgecolor= "red",tick_label=["fisrt month", "second month", "third month", "forth month", "fifth month"])plt.barh(index, y, height=0.3, edgecolor="red", tick_label=["fisrt month", "second month", "third month", "forth month", "fifth month"])plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/bar2.png" alt="纵向条形图"></p><p><img src="/images/matplotplit-notes/bar3.png" alt="横向条形图"></p><p>bar(self, x, height, width=0.8, bottom=None, <em>, align=”center”, *</em>kwargs)———纵向条形图</p><p>barh(y, width, height=0.8, left=None, <em>, align=”center”,  *</em>kwargs)———横向条形图</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>x</td><td>sequence of scalars</td></tr><tr><td>height</td><td>scalar or sequence of scalars</td></tr><tr><td>width</td><td>条形的宽度</td></tr><tr><td>bottom</td><td>y坐标的基值</td></tr><tr><td>align</td><td>{“center”, “edge”},x坐标的位置</td></tr><tr><td>color</td><td>柱状图表面颜色</td></tr><tr><td>edgecolor</td><td>柱状图边缘颜色</td></tr><tr><td>linewidth</td><td>线宽</td></tr><tr><td>tick_label</td><td>x坐标轴的记号，string or array-like</td></tr></tbody></table></div><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltN = 5y1 = [20, 10, 30, 25, 15]y2 = [15, 20, 10, 15, 25]index = np.arange(5)plt.bar(index, y1, width=0.3)plt.bar(index+0.3, y2, width=0.3)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/bar1.png" alt="横向双条形图"></p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltN = 5y1 = [20, 10, 30, 25, 15]y2 = [15, 20, 10, 15, 25]index = np.arange(5)plt.bar(index, y1, width=0.3)plt.bar(index, y2, width=0.3, bottom=y1)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/bar4.png" alt="层叠条形图"></p><h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>一系列高度不同的连续纵向条形组成</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltmu = 100sigma = 20x = mu + sigma*np.random.randn(2000)  # 生成正态分布（2000个数据）n, bins, patch = plt.hist(x, bins=100, color="#DDA0DD", edgecolor="black", density=True)y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (bins - mu))**2))print(y)plt.plot(bins, y, "--")plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/hist1.png" alt="hist1"></p><p>hist(self, x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype=’bar’, align=’mid’, orientation=’vertical’, rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, **kwargs)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>x</td><td>array or sequence of (n,) arrays,是一个数组或者数组序列</td></tr><tr><td>bins</td><td>整数（条形的个数），或者是序列（指定每一条的范围）</td></tr><tr><td>range</td><td>条形的上界和下界，范围之外的被舍弃</td></tr><tr><td>density</td><td>true(纵轴显示频率/组距)，false(纵轴显示频数)，即归一化处理</td></tr><tr><td>alpha</td><td>透明度</td></tr><tr><td>bottom</td><td>每一个柱子的基值</td></tr><tr><td>histtype</td><td>柱子类型，默认是bar</td></tr><tr><td>rwidth</td><td>柱子之间的距离，默认为零</td></tr><tr><td>edgecolor</td><td>柱子边界的颜色</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>n</td><td>落入每一个盒子的样本数</td></tr><tr><td>bins</td><td>每一个盒子边缘的值（一共n+1个值）</td></tr><tr><td>patched</td><td>每一个柱子</td></tr></tbody></table></div><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltx1 = np.random.normal(0, 0.8, 1000)  # 均值为0，标准差为0.8的正太分布x2 = np.random.normal(-2, 1, 1000)x3 =  np.random.normal(3, 2, 1000)kwargs = dict(histtype="stepfilled", alpha=0.5, density=True, bins=40)plt.hist(x1, **kwargs)plt.hist(x2, **kwargs)plt.hist(x3, **kwargs)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/hist2.png" alt="hist2"></p><h3 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltdef printf(val):    return "{:.2f}%".format(val)if __name__ == '__main__':    labels = ["SH", "BI", "SZ", "GD"]    fracs = [20, 10, 15, 5]    patches, tests, auto_tests = plt.pie(fracs, explode=[0, 0, 0.1, 0], labels=labels, autopct=printf)    plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/pie.png" alt="pie"></p><p>pie(self, x, explode=None, labels=None, colors=None,autopct=None, pctdistance=0.6, shadow=False, labeldistance=1.1,startangle=None, radius=None, counterclock=True, wedgeprops=None, textprops=None, center=(0, 0),frame=False, rotatelabels=False)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>x</td><td>array-like,The wedge sizes</td></tr><tr><td>explode</td><td>array-like，数组中每一个值是偏移中心位置的半径</td></tr><tr><td>label</td><td>每一个扇形的名称</td></tr><tr><td>colors</td><td>array-like, 指定每一个扇形的颜色</td></tr><tr><td>autopct</td><td>string, or function，标签化值</td></tr><tr><td>shadow</td><td>阴影</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>patches</td><td>A sequence of :class:<code>matplotlib.patches.Wedge</code> instances</td></tr><tr><td>texts</td><td>A list of the label :class:<code>matplotlib.text.Text</code> instances.</td></tr><tr><td>autotexts</td><td>A list of :class:<code>~matplotlib.text.Text</code> instances for the numericlabels. This will only be returned if the parameter <em>autopct</em> isnot <em>None</em>.</td></tr></tbody></table></div><h3 id="网格"><a href="#网格" class="headerlink" title="网格"></a>网格</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as npimport matplotlib.pyplot as pltx=np.arange(0,10,1)y=np.random.randn(len(x))fig=plt.figure()ax=fig.add_subplot(111)l1,=plt.plot(x,x,label="y=x")# l1.set_label("y=x")l2,=plt.plot(x,x*x,label="y=x^2")ax.legend(handles=[l1,l2],labels=["y=x","y=x^2"],loc=0)ax.grid(b=True,which='major',color='g', linestyle="--",linewidth=1)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/grid.png" alt="grid"></p><p>grid(self, b=None, which=’major’, axis=’both’, **kwargs)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>b</td><td>布尔值或者None，决定是否使用网格</td></tr><tr><td>which</td><td>更改的网格线</td></tr><tr><td>axis</td><td>应用网格线的轴</td></tr><tr><td>linestyle</td><td>线型</td></tr><tr><td>color</td><td>线的颜色</td></tr><tr><td>linewidth</td><td>线宽</td></tr></tbody></table></div><p>legend()<br>legend(labels)<br>legend(handles, labels)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>handles</td><td>线型序列</td></tr><tr><td>labels</td><td>字符串序列</td></tr><tr><td>loc</td><td>图例的位置（见官网）</td></tr><tr><td>ncol</td><td>图例按列排列的列数</td></tr></tbody></table></div><h2 id="二-matplotlib使用的三种方式"><a href="#二-matplotlib使用的三种方式" class="headerlink" title="二. matplotlib使用的三种方式"></a>二. matplotlib使用的三种方式</h2><h3 id="pyplot"><a href="#pyplot" class="headerlink" title="pyplot"></a>pyplot</h3><p>经典高层封装</p><ul><li><p>优点</p><p>简单易用，<strong>交互使用方便</strong>，可以根据命令实时作图</p></li><li><p>缺点</p><p>底层定制能力不足</p></li><li><p>设计代码</p></li><li><pre class="line-numbers language-lang-python"><code class="language-lang-python"># coding=utf-8import numpy as npimport matplotlib.pyplot as pltx = np.arange(0,10,1)y = np.random.randn(len(x))line= plt.plot(x, y, label="A")plt.title("pyplot")plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="pylab"><a href="#pylab" class="headerlink" title="pylab"></a>pylab</h3><p>不推荐使用</p><h3 id="面向对象的方式"><a href="#面向对象的方式" class="headerlink" title="面向对象的方式"></a>面向对象的方式</h3><ul><li><p>优点</p><p>接近matplotlib基础和底层的方式，难度较大，定制能力强</p></li><li><p>设计代码</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">from matplotlib import pyplot as pltimport numpy as npx = np.arange(0, 10, 1)y = np.random.randn(len(x))fig = plt.figure()  # 生成一张图ax1 = fig.add_subplot(421)l, = plt.plot(x, y)ax1.set_title("first figure")ax2 = fig.add_subplot(422)h, = plt.plot(x, y)ax2.set_title("first figure")plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="三-绘制多图"><a href="#三-绘制多图" class="headerlink" title="三. 绘制多图"></a>三. 绘制多图</h2><ul><li>matplotlib对象简介<ul><li>FigureCanvas：画图</li><li>Figure：图</li><li>Axes：坐标轴</li></ul></li><li>一张图生成多张子图</li></ul><pre class="line-numbers language-lang-python"><code class="language-lang-python">import matplotlib.pyplot as pltimport numpy as np# 子图x=np.arange(1,100)fig = plt.figure()  # 生成一张图ax1 = fig.add_subplot(221)  #总行数，总列数，子图所在位置ax1.plot(x,x)ax2 = fig.add_subplot(222)ax2.plot(x,-x)ax3 = fig.add_subplot(223)ax3.plot(x,x*x)ax4 = fig.add_subplot(224)ax4.plot(x,np.log(x))plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/add_subplot.png" alt="add_subplot"></p><p>add_subplot(nrows, ncols, index, **kwargs)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>nrows</td><td>子图的总行数</td></tr><tr><td>ncols</td><td>子图的总列数</td></tr><tr><td>index</td><td>子图的位置</td></tr><tr><td>label</td><td>返回轴的标签</td></tr></tbody></table></div><ul><li><p>生成多图</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import matplotlib.pyplot as plt# 多图（同一时间生成多张图）fig1=plt.figure()ax1=fig1.add_subplot(111)ax1.plot([1,2,3],[3,2,1])fig2=plt.figure()ax2=fig2.add_subplot(111)ax2.plot([1,2,3],[1,2,3])plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="4-通用操作函数"><a href="#4-通用操作函数" class="headerlink" title="4. 通用操作函数"></a>4. 通用操作函数</h2><h3 id="调整坐标轴范围"><a href="#调整坐标轴范围" class="headerlink" title="调整坐标轴范围"></a>调整坐标轴范围</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 调整坐标轴范围x = np.arange(-10,11,1)plt.plot(x,x*x)# axis参数：x轴最小坐标，x轴最大坐标，y轴最小坐标，y轴最大坐标x_min, x_max, y_min, y_max = plt.axis()# 调整坐标轴范围# plt.axis([-5,5,20,60])# 调整x轴：x轴最小坐标，x轴最大坐标# .xlim([-5,5])# 调整x轴的一端# plt.xlim(xmin = -5)# plt.xlim(xmax = 5)# 同理y轴# plt.ylim([0,60])plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="axis"><a href="#axis" class="headerlink" title="axis()"></a>axis()</h4><p>xmin, xmax, ymin, ymax = axis()</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>axis()</td><td>获取轴的最大最小坐标</td></tr></tbody></table></div><p>xmin, xmax, ymin, ymax = axis([xmin, xmax, ymin, ymax])</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>xmin,xmax,ymin,ymax</td><td>x轴最小坐标，x轴最大坐标，y轴最小坐标，y轴最大坐标</td></tr></tbody></table></div><p>xmin, xmax, ymin, ymax = axis(option)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>option</td><td>布尔值或者字符串，布尔值用于显示坐标轴与否，字符串用于设置坐标轴</td></tr></tbody></table></div><h4 id="plt方式的xlim-和ylim"><a href="#plt方式的xlim-和ylim" class="headerlink" title="plt方式的xlim()和ylim()"></a>plt方式的xlim()和ylim()</h4><ul><li><p>xlim()</p><p>获取或设置当前轴的x轴</p></li><li><p>ylim()</p><p>获取或设置当前轴的x轴</p></li></ul><h4 id="面向对象方式的set-xlim-和set-ylim"><a href="#面向对象方式的set-xlim-和set-ylim" class="headerlink" title="面向对象方式的set_xlim()和set_ylim()"></a>面向对象方式的set_xlim()和set_ylim()</h4><p>类似xlim()和ylim()</p><h3 id="调整坐标轴刻度"><a href="#调整坐标轴刻度" class="headerlink" title="调整坐标轴刻度"></a>调整坐标轴刻度</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as npimport matplotlib.pyplot as pltx=np.arange(0,10,1)y=np.random.randn(len(x))fig=plt.figure()ax=fig.add_subplot(111)l1,=plt.plot(x,x,label="y=x")l2,=plt.plot(x,x*x,label="y=x^2")# 调整坐标轴范围ax.set_xlim((0,8))ax.set_ylim(0,80)# 将轴平均分份（紧密程度）ax.locator_params(nbins=16)ax.legend(handles=[l1,l2],labels=["y=x","y=x^2"],loc=0)ax.grid(b=True,which='major',color='g', linestyle="--",linewidth=1)plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/locator_params.png" alt="locator_params"></p><p>locator_params(self, axis=’both’, tight=None, **kwargs)</p><div class="table-container"><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>axis</td><td>{‘both’, ‘x’, ‘y’}操作的轴</td></tr><tr><td>tight</td><td>bool or None, optional</td></tr></tbody></table></div><h3 id="添加坐标轴"><a href="#添加坐标轴" class="headerlink" title="添加坐标轴"></a>添加坐标轴</h3><pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as npimport matplotlib.pyplot as plt# 添加一个坐标轴，形成双坐标轴x = np.arange(2,20,1)y1 = x*xy2 = np.log(x)fig = plt.figure()ax1 = fig.add_subplot(121)ax1.plot(x, y1)ax1.set_ylabel('Y1')# 形成双坐标轴，x轴只有一个，y轴有两个ax2 = ax1.twinx()ax2.plot(x, y2 ,'r')ax2.set_ylabel('Y2')ax1.set_xlabel('Compare Y1 and Y2')ax3 = fig.add_subplot(122)ax3.plot(y1, x)ax3.set_ylabel("Y")ax3.set_xlabel("X1")# 形成双坐标轴，y轴只有一个，y轴有两个ax4 = ax3.twiny()ax4.plot(y2, x, "r")ax4.set_xlabel("X2")plt.tight_layout()  # 调整子图间的布局plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/matplotplit-notes/twinxy.png" alt="twinxy"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> python第三方库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据可视化 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
